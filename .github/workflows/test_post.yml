name: Test post now

on:
  workflow_dispatch:

jobs:
  post_now:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    env:
      TWITTER_API_KEY: ${{ secrets.TWITTER_API_KEY }}
      TWITTER_API_KEY_SECRET: ${{ secrets.TWITTER_API_KEY_SECRET }}
      TWITTER_ACCESS_TOKEN: ${{ secrets.TWITTER_ACCESS_TOKEN }}
      TWITTER_ACCESS_TOKEN_SECRET: ${{ secrets.TWITTER_ACCESS_TOKEN_SECRET }}
      PROVIDER_BASE_URL: ${{ secrets.PROVIDER_BASE_URL }}
      PROVIDER_API_KEY: ${{ secrets.PROVIDER_API_KEY }}
      PROVIDER_MODEL: ${{ secrets.PROVIDER_MODEL }}
      MAX_LENGTH: 220
      DRY_RUN_DEFAULT: 'false'
    steps:
      - name: Check out code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Configure LiteLLM/Ollama provider
        run: |
          if [ -z "${PROVIDER_API_KEY}" ] || [ -z "${PROVIDER_BASE_URL}" ] || [ -z "${PROVIDER_MODEL}" ]; then
            echo "Provider not configured (set PROVIDER_BASE_URL, PROVIDER_API_KEY, PROVIDER_MODEL)."
            echo "Expected: PROVIDER_BASE_URL=https://<your-cloudflared-url>/v1, PROVIDER_API_KEY=<local-secret>, PROVIDER_MODEL=ollama/llama3.1:8b-instruct"
            exit 1
          fi
          # Default model if not provided
          if [ -z "${PROVIDER_MODEL}" ]; then
            echo "PROVIDER_MODEL=ollama/llama3.1:8b-instruct" >> $GITHUB_ENV
          fi
          # Quick connectivity check
          curl -sSf -H "Authorization: Bearer ${PROVIDER_API_KEY}" "${PROVIDER_BASE_URL%/}/models" >/dev/null || {
            echo "Failed to reach provider at ${PROVIDER_BASE_URL}; ensure cloudflared tunnel is running to your LiteLLM server"; exit 1; }

      - name: Choose prompt
        id: choose
        shell: bash
        run: |
          PROMPT=$(python - <<'PY'
          import random, datetime
          now = datetime.datetime.utcnow()
          seed = int(now.strftime("%Y%m%d%H%M%S"))
          random.seed(seed)
          prompts = [
            "Drop a random motivational quote, feel free to look up one on the internet or make some shit up. Also be direct a use some vulgar language",
            "Share a direct, no-fluff motivational line about self-discipline, healthy masculinity, and respectful ways to treat women, point out the fact men should keep their options open and be very careful when picking partners. Keep it empowering, never demeaning, no slurs or hate; under 240 chars.",
            "Give a blunt tip on purpose, discipline, or delayed gratification. One line, under 240 chars.",
            "Write a short, gritty reminder about building masculine character: stoicism, responsibility, leading yourself first; always respectful to women. Under 240 chars.",
            "Punchy tweet on habits: consistency over intensity; choose one action today. Under 240 chars."
          ]
          print(random.choice(prompts))
          PY
          )
          echo "prompt<<EOF" >> $GITHUB_OUTPUT
          echo "$PROMPT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Post immediately with provider
        run: |
          python -m bot post "${{ steps.choose.outputs.prompt }}" --engine provider --no-dry-run || echo "post failed (empty generation or provider error)"
